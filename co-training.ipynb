{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load course fulltext\n",
    "path = 'course-cotrain-data/fulltext/course'\n",
    "course_fulltext = []\n",
    "for file in os.listdir(path):\n",
    "    with open(path + \"/\" + file, encoding=\"utf8\", errors='ignore') as f:\n",
    "        course_fulltext.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load non-course fulltext\n",
    "path = 'course-cotrain-data/fulltext/non-course'\n",
    "non_course_fulltext = []\n",
    "for file in os.listdir(path):\n",
    "    with open(path + \"/\" + file, encoding=\"utf8\", errors='ignore') as f:\n",
    "        non_course_fulltext.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load course links\n",
    "path = 'course-cotrain-data/inlinks/course'\n",
    "course_inlinks = []\n",
    "for file in os.listdir(path):\n",
    "    with open(path + \"/\" + file, encoding=\"utf8\", errors='ignore') as f:\n",
    "        course_inlinks.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load non-course links\n",
    "path = 'course-cotrain-data/inlinks/non-course'\n",
    "non_course_inlinks = []\n",
    "for file in os.listdir(path):\n",
    "    with open(path + \"/\" + file, encoding=\"utf8\", errors='ignore') as f:\n",
    "        non_course_inlinks.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulltext</th>\n",
       "      <th>inlinks</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;HTML&gt;&lt;HEAD&gt;\\n&lt;TITLE&gt;301 Moved Permanently&lt;/TI...</td>\n",
       "      <td>Computer Graphics Seminar \\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html&gt;\\n&lt;head&gt;\\n&lt;title&gt;CS 537 - Introduction t...</td>\n",
       "      <td>CS 537 Section 1 (Marvin Solomon) \\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;HTML&gt;\\n&lt;HEAD&gt;\\n&lt;TITLE&gt;CS 378 Course Descripti...</td>\n",
       "      <td>Object-Oriented Design and Programming \\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html&gt;\\n&lt;head&gt;\\n\\n&lt;title&gt;CSE 590S (Systems Sem...</td>\n",
       "      <td>590 S \\n590 S \\n590 S \\n590 S \\nCSE 590S \\n\\nC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;HTML&gt;\\n&lt;head&gt;\\n&lt;title&gt;CSE 370 Home Page (Autu...</td>\n",
       "      <td>CSE 370 \\nhere\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fulltext  \\\n",
       "0  <HTML><HEAD>\\n<TITLE>301 Moved Permanently</TI...   \n",
       "1  <html>\\n<head>\\n<title>CS 537 - Introduction t...   \n",
       "2  <HTML>\\n<HEAD>\\n<TITLE>CS 378 Course Descripti...   \n",
       "3  <html>\\n<head>\\n\\n<title>CSE 590S (Systems Sem...   \n",
       "4  <HTML>\\n<head>\\n<title>CSE 370 Home Page (Autu...   \n",
       "\n",
       "                                             inlinks  label  \n",
       "0                       Computer Graphics Seminar \\n      1  \n",
       "1               CS 537 Section 1 (Marvin Solomon) \\n      1  \n",
       "2          Object-Oriented Design and Programming \\n      1  \n",
       "3  590 S \\n590 S \\n590 S \\n590 S \\nCSE 590S \\n\\nC...      1  \n",
       "4                                   CSE 370 \\nhere\\n      1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_data = pd.DataFrame(\n",
    "    {'fulltext': course_fulltext,\n",
    "     'inlinks': course_inlinks,\n",
    "     'label': [1] * len(course_fulltext)\n",
    "    })\n",
    "\n",
    "course_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fulltext</th>\n",
       "      <th>inlinks</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;title&gt;Roy M. Jenevein, Jr.&lt;/title&gt;\\n\\n&lt;img sr...</td>\n",
       "      <td>Roy M. Jenevein, Jr. \\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html&gt;\\n&lt;head&gt;\\n&lt;title&gt;Stefan Savage&lt;/title&gt;\\n...</td>\n",
       "      <td>Stefan Savage\\nStefan Savage\\nStefan Savage\\nS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;TITLE&gt;Jeremy Stenglein's Home Page &lt;/TITLE&gt;\\n...</td>\n",
       "      <td>Stenglein, Jeremy \\nJeremy Stenglein\\nJeremy S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html&gt;\\n\\n&lt;head&gt;\\n&lt;title&gt;Kari Pulli's Home Pag...</td>\n",
       "      <td>Kari Pulli \\nKari Pulli \\nKari Pulli \\nPulli \\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html&gt;\\n&lt;!-- index.html file --&gt;\\n\\n&lt;title&gt;Nik...</td>\n",
       "      <td>Nikos P. Pitsianis \\nNikos Pitsianis\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fulltext  \\\n",
       "0  <title>Roy M. Jenevein, Jr.</title>\\n\\n<img sr...   \n",
       "1  <html>\\n<head>\\n<title>Stefan Savage</title>\\n...   \n",
       "2  <TITLE>Jeremy Stenglein's Home Page </TITLE>\\n...   \n",
       "3  <html>\\n\\n<head>\\n<title>Kari Pulli's Home Pag...   \n",
       "4  <html>\\n<!-- index.html file -->\\n\\n<title>Nik...   \n",
       "\n",
       "                                             inlinks  label  \n",
       "0                            Roy M. Jenevein, Jr. \\n      0  \n",
       "1  Stefan Savage\\nStefan Savage\\nStefan Savage\\nS...      0  \n",
       "2  Stenglein, Jeremy \\nJeremy Stenglein\\nJeremy S...      0  \n",
       "3    Kari Pulli \\nKari Pulli \\nKari Pulli \\nPulli \\n      0  \n",
       "4             Nikos P. Pitsianis \\nNikos Pitsianis\\n      0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_course_data = pd.DataFrame(\n",
    "    {'fulltext': non_course_fulltext,\n",
    "     'inlinks': non_course_inlinks,\n",
    "     'label': [0] * len(non_course_fulltext)\n",
    "    })\n",
    "\n",
    "non_course_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([course_data, non_course_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    821\n",
       "1    230\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html tags\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(0,len(data)):\n",
    "    data.iloc[row,0] = strip_tags(data.iloc[row,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_stemming(data,col_name,stemmer):\n",
    "    df = data.copy()\n",
    "#     df[col_name] = df[col_name].apply(lambda x: re.sub('[^a-zA-Z]', ' ', str(x)))\n",
    "    df[col_name] = df[col_name].apply(lambda x: str(x).lower().split())\n",
    "    df[col_name] = df[col_name].apply(lambda x: [stemmer.stem(word) for word in x if word not in stopwords])\n",
    "    df[col_name + \"_final\"] = df[col_name].apply(lambda x: ' '.join(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "data = text_stemming(data, 'fulltext', porter_stemmer)\n",
    "data = text_stemming(data, 'inlinks', porter_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "bow_full = cv.fit_transform(data['fulltext_final']).toarray()\n",
    "bow_link = cv.fit_transform(data['inlinks_final']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataframe with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.label.reset_index(drop=True)\n",
    "X1 = bow_full\n",
    "X2 = bow_link\n",
    "\n",
    "df1 = pd.DataFrame(X1)\n",
    "df2 = pd.DataFrame(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = list(range(0,19746)) + ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 19747)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names1=list(range(0,17733)) #fulltext\n",
    "col_names2=list(range(17733,19746)) #links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 17733)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,col_names1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label\n",
    "X = df.loc[:,col_names1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = gnb.fit(X_train,y_train)\n",
    "pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9467680608365019"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with full text (12 pages: 3 course, 9 non-course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vajk/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y = df.label\n",
    "X = df.loc[:,col_names1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = X_train[X_train['label']==0].sample(9, random_state=42)\n",
    "df1 = X_train[X_train.label==1].sample(3, random_state=42)\n",
    "\n",
    "train = pd.concat([df0,df1])\n",
    "\n",
    "train_x = train.loc[:,train.columns != 'label']\n",
    "train_y = train.loc[:,train.columns == 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = gnb.fit(train_x,train_y.label)\n",
    "pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859315589353612"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1051, 2013)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,col_names2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.label\n",
    "X = df.loc[:,col_names2]\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = gnb.fit(X_train,y_train)\n",
    "pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5247148288973384"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with links (12 pages: 3 course, 9 non-course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vajk/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y = df.label\n",
    "X = df.loc[:,col_names2]\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = X_train[X_train['label']==0].sample(9, random_state=42)\n",
    "df1 = X_train[X_train.label==1].sample(3, random_state=42)\n",
    "\n",
    "train = pd.concat([df0,df1])\n",
    "\n",
    "train_x = train.loc[:,train.columns != 'label']\n",
    "train_y = train.loc[:,train.columns == 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = gnb.fit(train_x,train_y.label)\n",
    "pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7870722433460076"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With U0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_training1(L, U, col_names1, col_names2, clf1, clf2,u=75, k=30,p=1,n=3, label='label', random_state=None):\n",
    "    '''\n",
    "    L - labeled data\n",
    "    U - unlabeled data\n",
    "    col_names1 - columns for clf1\n",
    "    col_names2 - columns for clf2\n",
    "    clf1 - classificator1\n",
    "    clf2 - classificator2\n",
    "    u - number of unlabeled data for training\n",
    "    k - number of iteration\n",
    "    p - number of positive examles to add label per iteration\n",
    "    n - number of negative examles to add label per iteration\n",
    "    label - name of column in L whit label\n",
    "    '''\n",
    "    \n",
    "    U0 = U.sample(u, random_state= random_state)\n",
    "    U.drop(U0.index, inplace=True)\n",
    "    while k > 0:\n",
    "        print(\"iteration: \", 30 - k)\n",
    "        # step 1: Use L to train a classifier h1 that considers only the x1 portion of x\n",
    "        clf1 = clf1.fit(L[col_names1],  L[label])\n",
    "        \n",
    "        # step 2: Use L, to train a classifier h2 that considers only the x2 portion of x\n",
    "        clf2 = clf2.fit(L[col_names2], L[label])\n",
    "        \n",
    "        # step 3: Allow hl to label p positive and n negative examples from U’\n",
    "        predicted_prob1 = clf1.predict_proba(U0[col_names1])\n",
    "        top_positive1 = predicted_prob1[:,1].argsort()[-p:]\n",
    "        top_negative1 = predicted_prob1[:,0].argsort()[-n:]\n",
    "        \n",
    "        # step 4: Allow hl to label p positive and n negative examples from U’\n",
    "        predicted_prob2 = clf2.predict_proba(U0[col_names2])\n",
    "        top_positive2 = predicted_prob2[:,1].argsort()[-p:]\n",
    "        top_negative2 = predicted_prob2[:,0].argsort()[-n:]    \n",
    "        \n",
    "        # step 5: Add these self-labeled examples to L\n",
    "        positive_ind = U0.iloc[np.unique(np.concatenate((top_positive1,top_positive2))),:].index\n",
    "        negative_ind = U0.iloc[np.unique(np.concatenate((top_negative1,top_negative2))),:].index\n",
    "        self_labeled = U0.loc[np.unique(np.concatenate((positive_ind,negative_ind))),:]\n",
    "        U0.drop(self_labeled.index, inplace=True)\n",
    "        self_labeled.loc[positive_ind, label] = 1\n",
    "        self_labeled.loc[negative_ind, label] = 0\n",
    "        L = pd.concat([L, self_labeled])\n",
    "    \n",
    "        # step 6: Randomly choose 2p + 2n examples from U to replenish U_\n",
    "        new_unlabeled = U.sample(2 * n + 2 * p, random_state=random_state)\n",
    "        U.drop(new_unlabeled.index, inplace=True)\n",
    "        U0 = U0.append(new_unlabeled)\n",
    "\n",
    "        k -= 1\n",
    "    \n",
    "    return [clf1,clf2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without U0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_training(L, U, col_names1, col_names2, clf1, clf2,u=75, k=30,p=1,n=3, label='label', random_state=None):\n",
    "    '''\n",
    "    L - labeled data\n",
    "    U - unlabeled data\n",
    "    col_names1 - columns for clf1\n",
    "    col_names2 - columns for clf2\n",
    "    clf1 - classificator1\n",
    "    clf2 - classificator2\n",
    "    u - number of unlabeled data for training\n",
    "    k - number of iteration\n",
    "    p - number of positive examles to add label per iteration\n",
    "    n - number of negative examles to add label per iteration\n",
    "    label - name of column in L whit label\n",
    "    '''\n",
    "    \n",
    "#     U0 = U.sample(u, random_state= random_state)\n",
    "#     U.drop(U0.index, inplace=True)\n",
    "    k0 = k\n",
    "    while k > 0:\n",
    "        print(\"iteration: \", k0 - k)\n",
    "        # step 1: Use L to train a classifier h1 that considers only the x1 portion of x\n",
    "        clf1 = clf1.fit(L[col_names1],  L[label])\n",
    "        \n",
    "        # step 2: Use L, to train a classifier h2 that considers only the x2 portion of x\n",
    "        clf2 = clf2.fit(L[col_names2], L[label])\n",
    "        \n",
    "        # step 3: Allow hl to label p positive and n negative examples from U\n",
    "        predicted_prob1 = clf1.predict_proba(U[col_names1])\n",
    "        top_positive1 = predicted_prob1[:,1].argsort()[-p:]\n",
    "        top_negative1 = predicted_prob1[:,0].argsort()[-n:]\n",
    "        \n",
    "        # step 4: Allow hl to label p positive and n negative examples from U\n",
    "        predicted_prob2 = clf2.predict_proba(U[col_names2])\n",
    "        top_positive2 = predicted_prob2[:,1].argsort()[-p:]\n",
    "        top_negative2 = predicted_prob2[:,0].argsort()[-n:]    \n",
    "        \n",
    "        # step 5: Add these self-labeled examples to L\n",
    "        positive_ind = U.iloc[np.unique(np.concatenate((top_positive1,top_positive2))),:].index\n",
    "        negative_ind = U.iloc[np.unique(np.concatenate((top_negative1,top_negative2))),:].index\n",
    "        self_labeled = U.loc[np.unique(np.concatenate((positive_ind,negative_ind))),:]\n",
    "        U.drop(self_labeled.index, inplace=True)\n",
    "        self_labeled.loc[positive_ind, label] = 1\n",
    "        self_labeled.loc[negative_ind, label] = 0\n",
    "        L = pd.concat([L, self_labeled])\n",
    "    \n",
    "        # step 6: Randomly choose 2p + 2n examples from U to replenish U_\n",
    "#         new_unlabeled = U.sample(2 * n + 2 * p, random_state=random_state)\n",
    "#         U.drop(new_unlabeled.index, inplace=True)\n",
    "#         U0 = U0.append(new_unlabeled)\n",
    "\n",
    "        k -= 1\n",
    "    \n",
    "    return [clf1,clf2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train until there are unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_training2(L, U, col_names1, col_names2, clf1, clf2, label='label', random_state=None, treshhold=0.8):\n",
    "    '''\n",
    "    L - labeled data\n",
    "    U - unlabeled data\n",
    "    col_names1 - columns for clf1\n",
    "    col_names2 - columns for clf2\n",
    "    clf1 - classificator1\n",
    "    clf2 - classificator2\n",
    "    u - number of unlabeled data for training\n",
    "    k - number of iteration\n",
    "    p - number of positive examles to add label per iteration\n",
    "    n - number of negative examles to add label per iteration\n",
    "    label - name of column in L whit label\n",
    "    '''\n",
    "    \n",
    "    while len(U) > 0:\n",
    "        \n",
    "        # step 1: Use L to train a classifier h1 that considers only the x1 portion of x\n",
    "        clf1 = clf1.fit(L[col_names1],  L[label])\n",
    "        \n",
    "        # step 2: Use L, to train a classifier h2 that considers only the x2 portion of x\n",
    "        clf2 = clf2.fit(L[col_names2], L[label])\n",
    "        \n",
    "        # step 3: Allow hl to label p positive and n negative examples from U\n",
    "        predicted_prob1 = clf1.predict_proba(U[col_names1])\n",
    "        top_positive1 = predicted_prob1[:,1].argsort()[-1:] if predicted_prob1[:,1].argsort()[-1:] > treshhold else [] \n",
    "        top_negative1 = predicted_prob1[:,0].argsort()[-1:] if predicted_prob1[:,0].argsort()[-1:] > treshhold else []\n",
    "        \n",
    "        # step 4: Allow hl to label p positive and n negative examples from U\n",
    "        predicted_prob2 = clf2.predict_proba(U[col_names2]) \n",
    "        top_positive2 = predicted_prob2[:,1].argsort()[-1:] if predicted_prob2[:,1].argsort()[-1:] > treshhold else []\n",
    "        top_negative2 = predicted_prob2[:,0].argsort()[-1:] if predicted_prob2[:,0].argsort()[-1:] > treshhold else []\n",
    "        \n",
    "        # step 5: Add these self-labeled examples to L\n",
    "        if(np.unique(np.concatenate((top_positive1,top_positive2, top_negative1, top_negative2))).size == 0):\n",
    "            print(\"ehhhh\")\n",
    "            return [clf1,clf2]\n",
    "        positive_ind = U.iloc[np.unique(np.concatenate((top_positive1,top_positive2))),:].index\n",
    "        negative_ind = U.iloc[np.unique(np.concatenate((top_negative1,top_negative2))),:].index\n",
    "        self_labeled = U.loc[np.unique(np.concatenate((positive_ind,negative_ind))),:]\n",
    "        U.drop(self_labeled.index, inplace=True)\n",
    "        self_labeled.loc[positive_ind, label] = 1\n",
    "        self_labeled.loc[negative_ind, label] = 0\n",
    "        L = pd.concat([L, self_labeled])\n",
    "    \n",
    "        # step 6: Randomly choose 2p + 2n examples from U to replenish U_\n",
    "#         new_unlabeled = U.sample(2 * n + 2 * p, random_state=random_state)\n",
    "#         U.drop(new_unlabeled.index, inplace=True)\n",
    "#         U0 = U0.append(new_unlabeled)\n",
    "\n",
    "    \n",
    "    return [clf1,clf2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedClassifier:\n",
    "    \n",
    "    def __init__(self,clf1, clf2, cols1, cols2):\n",
    "        self.clf1 = clf1\n",
    "        self.clf2 = clf2\n",
    "        self.cols1 = cols1\n",
    "        self.cols2 = cols2\n",
    "        \n",
    "    def pr(self, df):\n",
    "        result = []\n",
    "        for ind, row in df.iterrows():\n",
    "            prob0 = self.clf1.predict_proba([df.loc[ind,self.cols1]])[0][0] * self.clf2.predict_proba([df.loc[ind,self.cols2]])[0][0]  \n",
    "            prob1 = self.clf1.predict_proba([df.loc[ind,self.cols1]])[0][1] * self.clf2.predict_proba([df.loc[ind,self.cols2]])[0][1]\n",
    "#             print(self.clf1.predict_proba([df.loc[ind,self.cols1]]), \" \", self.clf1.predict_proba([df.loc[ind,self.cols1]])[0][0], \" \", self.clf2.predict_proba([df.loc[ind,self.cols2]]))\n",
    "#             print(prob0, \" \", prob1)\n",
    "            res = 0 if prob0 > prob1 else 1\n",
    "            result.append(res)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vajk/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y = df.label\n",
    "X = df[df.columns.drop('label')]\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train['label'] = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labeled data, 12 pages (3 course, 9 non course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = X_train[X_train.label==0].sample(9)#, random_state= 42)\n",
    "\n",
    "train1 = X_train[X_train.label==1].sample(3)#, random_state=42)\n",
    "\n",
    "train = pd.concat([train0,train1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405    0\n",
       "685    0\n",
       "634    0\n",
       "953    0\n",
       "724    0\n",
       "879    0\n",
       "360    0\n",
       "379    0\n",
       "752    0\n",
       "225    1\n",
       "171    1\n",
       "147    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb1 = MultinomialNB()\n",
    "gnb2 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators = 100, max_depth = 8, random_state=42)\n",
    "clf2 = RandomForestClassifier(n_estimators = 100, max_depth = 8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial bayes co-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "iteration:  1\n",
      "iteration:  2\n",
      "iteration:  3\n",
      "iteration:  4\n",
      "iteration:  5\n",
      "iteration:  6\n",
      "iteration:  7\n",
      "iteration:  8\n",
      "iteration:  9\n",
      "iteration:  10\n",
      "iteration:  11\n",
      "iteration:  12\n",
      "iteration:  13\n",
      "iteration:  14\n",
      "iteration:  15\n",
      "iteration:  16\n",
      "iteration:  17\n",
      "iteration:  18\n",
      "iteration:  19\n",
      "iteration:  20\n",
      "iteration:  21\n",
      "iteration:  22\n",
      "iteration:  23\n",
      "iteration:  24\n",
      "iteration:  25\n",
      "iteration:  26\n",
      "iteration:  27\n",
      "iteration:  28\n",
      "iteration:  29\n"
     ]
    }
   ],
   "source": [
    "new_1, new_2 = co_training(L=train,U=X_train.loc[X_train.index.drop(train.index),list(range(0,19746))], \n",
    "                           col_names1=list(range(0,17733)),\n",
    "                           col_names2=list(range(17733,19746)), clf1=gnb1, clf2=gnb2, k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_1.predict(X_test[col_names1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text calssifier accuracy: 0.8973384030418251\n"
     ]
    }
   ],
   "source": [
    "print(\"text calssifier accuracy:\" ,accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link calssifier accuracy: 0.3726235741444867\n"
     ]
    }
   ],
   "source": [
    "pred = new_2.predict(X_test[col_names2])\n",
    "print(\"link calssifier accuracy:\" ,accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = CombinedClassifier(new_1,new_2,col_names1, col_names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = cl.pr(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined calssifier accuracy: 0.8631178707224335\n"
     ]
    }
   ],
   "source": [
    "print(\"combined calssifier accuracy:\" ,accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "iteration:  1\n",
      "iteration:  2\n",
      "iteration:  3\n",
      "iteration:  4\n",
      "iteration:  5\n",
      "iteration:  6\n",
      "iteration:  7\n",
      "iteration:  8\n",
      "iteration:  9\n",
      "iteration:  10\n",
      "iteration:  11\n",
      "iteration:  12\n",
      "iteration:  13\n",
      "iteration:  14\n",
      "iteration:  15\n",
      "iteration:  16\n",
      "iteration:  17\n",
      "iteration:  18\n",
      "iteration:  19\n",
      "iteration:  20\n",
      "iteration:  21\n",
      "iteration:  22\n",
      "iteration:  23\n",
      "iteration:  24\n",
      "iteration:  25\n",
      "iteration:  26\n",
      "iteration:  27\n",
      "iteration:  28\n",
      "iteration:  29\n"
     ]
    }
   ],
   "source": [
    "new_1, new_2 = co_training(L=train,U=X_train.loc[X_train.index.drop(train.index),list(range(0,19746))], \n",
    "                           col_names1=list(range(0,17733)),\n",
    "                           col_names2=list(range(17733,19746)), clf1=clf1, clf2=clf2, k=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fulltext calssifier accuracy: 0.8365019011406845\n"
     ]
    }
   ],
   "source": [
    "pred = new_1.predict(X_test[col_names1])\n",
    "print(\"fulltext calssifier accuracy:\" ,accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link calssifier accuracy: 0.779467680608365\n"
     ]
    }
   ],
   "source": [
    "pred = new_2.predict(X_test[col_names2])\n",
    "print(\"link calssifier accuracy:\" ,accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = CombinedClassifier(new_1,new_2,col_names1, col_names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = cl.pr(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined calssifier accuracy: 0.8022813688212928\n"
     ]
    }
   ],
   "source": [
    "print(\"combined calssifier accuracy:\" ,accuracy_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
