
===========================================================================================================
Combining Labeled and Unlabeled Data with Co-Training
===========================================================================================================








===========================================================================================================
Analyzing the Effectiveness and Applicability of Co-training
===========================================================================================================

CO-TRAINING Setting
	- co-training setting sa aplikuje v prípade, že dataset má prirodzene oddelenie (division of) features:
		- webové stránky môžu byť popísané buď:
			- textom nachádzajúcim sa na danej webovej stránke
			- alebo textom hyperlinky, ktorý ukazuje na danú webovú stránku
	- tradičné algoritmy používané pre učenie sa v tejto doméne ignorujú možnosť oddeleného pohľadu a dajú všetky features dokopy
	- avšak algoritmus používajúci co-training setting môže naučiť samostatné klasifikátori pre každý feature set a následne skombinovať ich predikcie s cieľom znížiť chybu klasifikácie
	- co-training algorimty používajúce labeled a unlabeled data explicitne nastavujú toto rozdelenie počas učenia
	- pre použitie co-training nastavenia je potrebné splnenie niektorých predpokladov:
		(1) instance distribution is compatible with target function:
			- target function = funkcia pomocou ktorej sa nad každým feature setom predukuje rovnaký label
				- v prípade domény webu, trieda inštancie by mala byť identifikovateľná použitím buď textu hyperlinky alebo stránkou samotnou
		(2) features v jednom sete inštancie sú podmienene nezávislé (conditionally independent) vzhľadom na features v druhom sete
			- v reálnom svete to môže byť nereálny predpoklad:
				- napríklad slová na webovej stránke nemôžu byť related k slovám na hyperlinke, okrem classy web stránky
	- real-world datasety s feature division nemusia plne spĺňať strikné podmienky kompatibility a podmiennej nezávislosti
		- dôležitá je preto otázka - ako citlivé sú co-training algoritmy vzhľadom na korektnosť/naplnenie stanovených predpokladov
	- proces:
		- v tomto článku používali naive Bayes
		- Inputs: Vstupná kolekcia olabelovaných dokumentov a kolekcia neolabelovaných (každý klasifikátor je inicializovaný použitím iba niekoľkokých olabelovaných dokumentov)
		- Loop (pokiaľ existuje dokument, ktorý nemá label):
			- vytvor klasifikátor A používajúc časť dokumentov prislúchajúcich tomuto klasifikátoru
			- vytvor klasifikátor B používajúc časť dokumentov prislúchajúcich tomuto klasifikátoru
			- pre každú triedu C, zober neolabelovaný dokument, o ktorého labeli si je klasifikátor A najistejší, pridel label a zaraď dokument do kolekcie o labelovaných dokumentov (to isté s klasifikátorom B)
		- Output:
			- dva klasifikátori A a B predikujúce class labels pre nové dokumenty. Predikcie môžu byť kombinované násobením a následnou renormalizáciou skore pravdepodobnosti pre triedu
	- WebKB Course dataset
		- Blum and Mitchel [1] priniesli výsledky experimentu, v ktorom porovnávali co-training algoritmus s olabelovanými a neolabelovanými dátami voči naive Bayes používajúceho iba olabelované dáta
		- WebKB Course dataset = kolekcia 1051 webových stránoch zozbieraných z computer science oddelení na 4 univerzitách
		- TASK:
			- identifikovať stránky, ktoré sú home pages academických kurzov
			- každý example sa skladá súčasne zo slov, ktoré sa nachádzajú na stránke a rovnako zo slov nachádzajúich sa v anchor texte hyperlinky ukazujúcej na tú stránku
		- Co-training algoritmus používa túto partíciu (stránka vs hyperlinka)
		- EM (Expectation-Maximization - treba asi ešte opísať!!!) zmiešava tieto features dokopy (napr. slovo career má dve features - "career-body" a "career-hyperlink")
		- testovaním co-traing, EM a Naive Bayesa zistili, že co-training si počínal najhoršie
			- dôvodov mohlo byť viacero a však jedna z nich je aj rozdelenie features, ktoré nemuselo byť dostatočne nezávislé
			- pustili sa do overovania vytvorením datasetu, ktorý má skutočne nezávislé rozdelenie features a naozaj overili, že v prípade dvoch feature setov majúcich skutočnú nezávislosť, prináša co-training značné zlepšenie v porovnaní s EM (error rate 3.9% vs 8.9%)
				- nie je to však možné prehlásiť všeobecne
				- tieto dva algoritmy sú značne odlišné:
					- co-training labeluje iba niekoľko dokumentov per round = inkrementálne používa neolabelované dáta
					- EM pravdepodobnostne labeluje všetky dáta per round = iteratívne používa neolabelované dáta
					- výhoda, respektíve vyššia úspešnosť dosiahnutá co-traingom môže byť podmienená viac týmto rozdielom než používaním rozdelených features
					- potvrdili predošlé tvrdenie aj zohľadňujúc túto skutočnosť
	- použitie co-trainingu na bežný dataset
		- napriek tomu, že ide o veľmi silný nástroj, nie je všeobecne použiteľný
		- relatívne málo datasetov prichádza so známym a prirozdeným rozdelením features, ktoré môžu rozumne pomôcť klasifikácií
		- väčšina datasetov má jeden set features bez žiadnej možnosti jasnej a prirozdenej možnosti ako ich rozdeliť
		- v prípade, že je možné nájsť spôsob rozdelenia, a dostatočne splniť podmienku o nezávislosti, co-training môže priniesť značnú výhodu




	They argue that a weak initial hypothesis over one feature set can be used to label instances. These instances seem randomly distributed to the other classiffer (by the conditional independence assumption), but have classiffcation noise from the weak hypothesis. Thus, an algorithm that can learn in the presence of classiffcation noise will succeed at learning from these labeled instances.
